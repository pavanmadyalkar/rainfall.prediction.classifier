{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "prev_pub_hash": "6a00a703e123bddd6178a90cb7938f215f09b4ca3e08ba1f30d34b01603dd863"
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Building a Rainfall Prediction Classifier\n\n## Aim\nTo develop a binary classification model using `logistic regression` & using `Random Forest` that predicts & compares the likelihood of rainfall based on meteorological features such as temperature, humidity, wind speed, and atmospheric pressure.\n\n## Objectives\n- Collect and preprocess historical weather data relevant to rainfall prediction.\n- Select key features that influence rainfall occurrence.\n- Build a logistic regression model to classify whether it will rain or not.\n- Evaluate model performance using metrics like accuracy, precision, recall, and confusion matrix.\n- Interpret model coefficients to understand the impact of each feature on rainfall prediction.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# About The Dataset\nThe original source of the data is Australian Government's Bureau of Meteorology and the latest data can be gathered from [http://www.bom.gov.au/climate/dwo/](http://www.bom.gov.au/climate/dwo/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork20718538-2022-01-01).\n\nThe dataset you'll use in this project was downloaded from Kaggle at [https://www.kaggle.com/datasets/jsphyg/weather-dataset-rattle-package/](https://www.kaggle.com/datasets/jsphyg/weather-dataset-rattle-package?resource=download&select=weatherAUS.csv)  \nColumn definitions were gathered from [http://www.bom.gov.au/climate/dwo/IDCJDW0000.shtml](http://www.bom.gov.au/climate/dwo/IDCJDW0000.shtml?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork20718538-2022-01-01)  \n\nThe dataset contains observations of weather metrics for each day from 2008 to 2017, and includes the following fields:\n\n| Field         | Description                                           | Unit            | Type   |\n| :------------ | :---------------------------------------------------- | :-------------- | :----- |\n| Date          | Date of the Observation in YYYY-MM-DD                 | Date            | object |\n| Location      | Location of the Observation                           | Location        | object |\n| MinTemp       | Minimum temperature                                   | Celsius         | float  |\n| MaxTemp       | Maximum temperature                                   | Celsius         | float  |\n| Rainfall      | Amount of rainfall                                    | Millimeters     | float  |\n| Evaporation   | Amount of evaporation                                 | Millimeters     | float  |\n| Sunshine      | Amount of bright sunshine                             | hours           | float  |\n| WindGustDir   | Direction of the strongest gust                       | Compass Points  | object |\n| WindGustSpeed | Speed of the strongest gust                           | Kilometers/Hour | object |\n| WindDir9am    | Wind direction averaged over 10 minutes prior to 9am  | Compass Points  | object |\n| WindDir3pm    | Wind direction averaged over 10 minutes prior to 3pm  | Compass Points  | object |\n| WindSpeed9am  | Wind speed averaged over 10 minutes prior to 9am      | Kilometers/Hour | float  |\n| WindSpeed3pm  | Wind speed averaged over 10 minutes prior to 3pm      | Kilometers/Hour | float  |\n| Humidity9am   | Humidity at 9am                                       | Percent         | float  |\n| Humidity3pm   | Humidity at 3pm                                       | Percent         | float  |\n| Pressure9am   | Atmospheric pressure reduced to mean sea level at 9am | Hectopascal     | float  |\n| Pressure3pm   | Atmospheric pressure reduced to mean sea level at 3pm | Hectopascal     | float  |\n| Cloud9am      | Fraction of the sky obscured by cloud at 9am          | Eights          | float  |\n| Cloud3pm      | Fraction of the sky obscured by cloud at 3pm          | Eights          | float  |\n| Temp9am       | Temperature at 9am                                    | Celsius         | float  |\n| Temp3pm       | Temperature at 3pm                                    | Celsius         | float  |\n| RainToday     | If there was at least 1mm of rain today               | Yes/No          | object |\n| RainTomorrow  | If there is at least 1mm of rain tomorrow             | Yes/No          | object |\n\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Install and import the required libraries\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Exectue the following cells to install and import the necessary libraries.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "!pip install numpy\n!pip install pandas\n!pip install matplotlib\n!pip install scikit-learn\n!pip install seaborn",
      "metadata": {
        "scrolled": true,
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\nimport seaborn as sns",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Load the data\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Execute the following cells to load the dataset as a pandas dataframe.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "url=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/_0eYOqji3unP1tDNKWZMjg/weatherAUS-2.csv\"\ndf = pd.read_csv(url)\ndf.head()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "df.count()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Sunshine and cloud cover seem like important features, but they have a lot of missing values, far too many to impute their missing values.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Drop all rows with missing values\nTo try to keep things simple we'll drop rows with missing values and see what's left\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df = df.dropna()\ndf.info()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Since we still have 56k observations left after dropping missing values, we may not need to impute any missing values.  \nLet's see how we do.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df.columns",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Data leakage considerations\nIf we adjust our approach and aim to predict todayâ€™s rainfall using historical weather data up to and including yesterday, then we can legitimately utilize all of the available features. This shift would be particularly useful for practical applications, such as deciding whether you will bike to work today.\n\nWith this new target, we should update the names of the rain columns accordingly to avoid confusion.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df = df.rename(columns={'RainToday': 'RainYesterday',\n                        'RainTomorrow': 'RainToday'\n                        })",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Data Granularity\nMost of the time patterns do not have the same predictability in vastly different locations in Australia.\nThe chance of rain in one location can be much higher than in another.\nUsing all of the locations requires a more complex model as it needs to adapt to local weather patterns.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Location selection\n\nHence group these three locations together and use only their weather data to build our localized prediction model.  \nBecause there might still be some slight variations in the weather patterns we'll keep `Location` as a categorical variable.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df = df[df.Location.isin(['Melbourne','MelbourneAirport','Watsonia',])]\ndf. info()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "We still have 7557 records, which should be enough to build a reasonably good model.  \nWe could always gather more data if needed by partioning the data into similar locations or simplyby updating it from the source to include a larger time frame.\n\n## Extracting a seasonality feature\nNow consider the `Date` column. We expect the weather patterns to be seasonal, having different predictablitiy levels in winter and summer for example.  \nThere may be some variation with `Year` as well, but we'll leave that out for now.\nLet's engineer a `Season` feature from `Date` and drop `Date` afterward, since it is most likely less informative than season. \nAn easy way to do this is to define a function that assigns seasons to given months, then use that function to transform the `Date` column.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Create a function to map dates to seasons\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def date_to_season(date):\n    month = date.month\n    if (month == 12) or (month == 1) or (month == 2):\n        return 'Summer'\n    elif (month == 3) or (month == 4) or (month == 5):\n        return 'Autumn'\n    elif (month == 6) or (month == 7) or (month == 8):\n        return 'Winter'\n    elif (month == 9) or (month == 10) or (month == 11):\n        return 'Spring'",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Map the dates to seasons and drop the Date column",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Write your response.\ndf['Date'] = pd.to_datetime(df['Date'])\n\ndf['Season'] = df['Date'].apply(date_to_season)\n\ndf = df.drop(columns=['Date'])\ndf",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Define the feature and target dataframes",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "X = df.drop(columns=['RainToday'], axis=1)\ny = df['RainToday']",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Split data into training and test sets, ensuring target stratification",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Define preprocessing transformers for numerical and categorical features",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "numeric_features = X_train.select_dtypes(include=['number']).columns.tolist()\ncategorical_features = X_train.select_dtypes(include=['object', 'category']).columns.tolist()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Define separate transformers for both feature types and combine them into a single preprocessing transformer\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Scale the numeric features\nnumeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n\n# One-hot encode the categoricals \ncategorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Combine the transformers into a single preprocessing column transformer\nColumnTransformer apply different transformations to different columns of a DataFrame\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "preprocessor = ColumnTransformer(transformers=[\n    ('num', numeric_transformer, numeric_features),\n    ('cat', categorical_transformer, categorical_features)\n])",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Create a pipeline by combining the preprocessing with a Random Forest classifier",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "pipeline = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('classifier', RandomForestClassifier(random_state=42))\n])",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Define a parameter grid to use in a cross validation grid search model optimizer\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "param_grid = {\n    'classifier__n_estimators': [50, 100],\n    'classifier__max_depth': [None, 10, 20],\n    'classifier__min_samples_split': [2, 5]\n}",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Pipeline usage in crossvalidation\nRecall that the pipeline is repeatedly used within the crossvalidation by fitting on each internal training fold and predicting on its corresponding validation fold\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Performing grid search cross-validation and fit the best model to the training data\n### Select a cross-validation method, ensuring target stratification during validation\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "cv = StratifiedKFold(n_splits=5, shuffle=True)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=cv, scoring='accuracy', verbose=2)\ngrid_search.fit(X_train, y_train)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Print the best parameters and best crossvalidation score\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "print(\"\\nBest parameters found: \", grid_search.best_params_)\nprint(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Display model's estimated score",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "test_score = grid_search.score(X_test, y_test)\nprint(\"Test set score: {:.2f}\".format(test_score))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "So we have a reasonably accurate classifer, which is expected to correctly predict about 84% of the time whether it will rain today in the Melbourne area.  \nBut careful here. Let's take a deeper look at the results.\n\nThe best model is stored within the gridsearch object.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Get the model predictions from the grid search estimator on the unseen data",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "y_pred = grid_search.predict(X_test)\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_test, y_pred))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Plot the confusion matrix \n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "## Write your response.\nconf_matrix = confusion_matrix(y_test, y_pred)\ndisp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix)\ndisp.plot(cmap='Blues')\nplt.title('Confusion Matrix')\nplt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Extract the feature importances",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "feature_importance = grid_search.best_estimator_['classifier'].feature_importances_",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Now let's extract the feature importances and plot them as a bar graph.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Combine numeric and categorical feature names\nfeature_names = numeric_features + list(grid_search.best_estimator_['preprocessor']\n                                        .named_transformers_['cat']\n                                        .named_steps['onehot']\n                                        .get_feature_names_out(categorical_features))\n\nfeature_importances = grid_search.best_estimator_['classifier'].feature_importances_\n\nimportance_df = pd.DataFrame({'Feature': feature_names,\n                              'Importance': feature_importances\n                             }).sort_values(by='Importance', ascending=False)\n\nN = 20  # Change this number to display more or fewer features\ntop_features = importance_df.head(N)\n\n# Plotting\nplt.figure(figsize=(10, 6))\nplt.barh(top_features['Feature'], top_features['Importance'], color='skyblue')\nplt.gca().invert_yaxis()  # Invert y-axis to show the most important feature on top\nplt.title(f'Top {N} Most Important Features in predicting whether it will rain today')\nplt.xlabel('Importance Score')\nplt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Point to note - 3\nIdentify the most important feature for predicting whether it will rain based on the feature importance bar graph. There will be a question on this in the assignment that follows.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Update the pipeline and the parameter grid with Logistic Regression\nUpdate the pipeline and the parameter grid and train a Logistic Regression model and compare the performance of the two models. We'll need to replace the clasifier with LogisticRegression. We have supplied the parameter grid for you.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "pipeline.set_params(classifier=LogisticRegression(random_state=42))\ngrid_search.estimator = pipeline\nparam_grid = {\n    'classifier__solver' : ['liblinear'],\n    'classifier__penalty': ['l1', 'l2'],\n    'classifier__class_weight' : [None, 'balanced']\n}\ngrid_search.param_grid = param_grid\ngrid_search.fit(X_train, y_train)\ny_pred = grid_search.predict(X_test)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "###  Compare the results to previous model.\nDisplay the clasification report and the confusion matrix for the new model and compare your results with the previous model.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "print(classification_report(y_test, y_pred))\n\n# Generate the confusion matrix \nconf_matrix = confusion_matrix(y_test, y_pred)\n\nplt.figure()\nsns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='d')\n\n# Set the title and labels\nplt.title('Rainfall Classification Confusion Matrix')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\n\n# Show the plot\nplt.tight_layout()\nplt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Model performs very well on the majority class (\"No\").\nHigh precision (0.86) and recall (0.93) for \"No\" means it rarely misclassifies dry days.\nLower recall (0.51) for \"Yes\" means it's missing nearly half of the rainy days.\nF1-score for \"Yes\" is 0.58, which is moderate but could be improved.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Overall Accuracy: Random Forest is slightly better (84% vs. 83%).\n\n`Logistic Regression`\nNo: 1,073 correct predictions out of 1,154\nYes: 182 correct predictions out of 358\n\n`Random Forest`\nNo: 1,084 correct predictions out of 1,154\nYes: 186 correct predictions out of 358\n\nThe true positive rate of LogisticRegression Classifier.\n0.51",
      "metadata": {}
    }
  ]
}